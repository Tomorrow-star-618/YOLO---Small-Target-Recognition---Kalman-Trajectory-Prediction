"""
ç›¸æœºè¿åŠ¨è¡¥å¿è·Ÿè¸ªç³»ç»Ÿæµ‹è¯•ç¨‹åº
å®Œæ•´çš„æµ‹è¯•å’Œæ€§èƒ½è¯„ä¼°
"""

import cv2
import numpy as np
import os
import sys
import time
from datetime import datetime

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.append(os.path.dirname(os.path.dirname(__file__)))

from ultralytics import YOLO
from camera_motion_compensation.motion_compensated_multi_tracker import MotionCompensatedMultiTracker
from kalman.trajectory_visualizer import TrajectoryVisualizer

class CameraMotionCompensationTestSystem:
    """
    ç›¸æœºè¿åŠ¨è¡¥å¿æµ‹è¯•ç³»ç»Ÿ
    
    æµ‹è¯•åŠŸèƒ½ï¼š
    1. å¯¹æ¯”åŸå§‹è·Ÿè¸ªvsè¿åŠ¨è¡¥å¿è·Ÿè¸ª
    2. æ€§èƒ½è¯„ä¼°å’Œç»Ÿè®¡åˆ†æ  
    3. å¯è§†åŒ–æ•ˆæœå¯¹æ¯”
    4. è¯¦ç»†çš„æµ‹è¯•æŠ¥å‘Šç”Ÿæˆ
    """
    
    def __init__(self, model_path, conf_threshold=0.1):
        """åˆå§‹åŒ–æµ‹è¯•ç³»ç»Ÿ"""
        print("ğŸš€ åˆå§‹åŒ–ç›¸æœºè¿åŠ¨è¡¥å¿æµ‹è¯•ç³»ç»Ÿ...")
        
        # YOLOæ¨¡å‹
        self.model = YOLO(model_path)
        self.conf_threshold = conf_threshold
        
        # å¯è§†åŒ–å™¨
        self.visualizer = TrajectoryVisualizer()
        
        # æµ‹è¯•é…ç½®
        self.test_methods = [
            'optical_flow',
            'feature_matching', 
            'hybrid'
        ]
        
        # æµ‹è¯•ç»“æœ
        self.test_results = {}
        
        print("âœ… ç³»ç»Ÿåˆå§‹åŒ–å®Œæˆ")
    
    def run_single_test(self, video_path, output_dir, method='optical_flow', 
                       test_name="default"):
        """è¿è¡Œå•ä¸ªæµ‹è¯•"""
        print(f"\n{'='*60}")
        print(f"ğŸ§ª å¼€å§‹æµ‹è¯•: {test_name} - {method}")
        print(f"{'='*60}")
        
        # åˆ›å»ºè¾“å‡ºç›®å½•
        method_output_dir = os.path.join(output_dir, method)
        os.makedirs(method_output_dir, exist_ok=True)
        
        # åˆå§‹åŒ–è·Ÿè¸ªå™¨
        tracker = MotionCompensatedMultiTracker(
            max_lost_frames=150,
            min_hits=1,
            iou_threshold=0.1,
            motion_detection_method=method
        )
        
        # è§†é¢‘å¤„ç†
        cap = cv2.VideoCapture(video_path)
        if not cap.isOpened():
            print(f"âŒ æ— æ³•æ‰“å¼€è§†é¢‘: {video_path}")
            return None
        
        # è§†é¢‘ä¿¡æ¯
        fps = int(cap.get(cv2.CAP_PROP_FPS))
        width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
        height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
        
        print(f"ğŸ“º è§†é¢‘ä¿¡æ¯: {width}x{height}, {fps}fps, {total_frames}å¸§")
        
        # è¾“å‡ºè§†é¢‘
        output_video_path = os.path.join(method_output_dir, f"{test_name}_result.mp4")
        fourcc = cv2.VideoWriter_fourcc(*'mp4v')
        out = cv2.VideoWriter(output_video_path, fourcc, fps, (width, height))
        
        # å¤„ç†ç»Ÿè®¡
        frame_count = 0
        detection_count = 0
        tracking_stats = []
        processing_times = []
        
        start_time = time.time()
        
        while True:
            ret, frame = cap.read()
            if not ret:
                break
            
            frame_start = time.time()
            
            # YOLOæ£€æµ‹
            results = self.model(frame, verbose=False, conf=self.conf_threshold)
            
            # æå–æ£€æµ‹ç»“æœ
            detections = []
            if len(results) > 0 and results[0].boxes is not None and len(results[0].boxes) > 0:
                boxes = results[0].boxes.xyxy.cpu().numpy()
                scores = results[0].boxes.conf.cpu().numpy()
                
                for box, score in zip(boxes, scores):
                    if score > self.conf_threshold:
                        detections.append([
                            float(box[0]), float(box[1]), 
                            float(box[2]), float(box[3]), 
                            float(score)
                        ])
            
            detection_count += len(detections)
            
            # è·Ÿè¸ªæ›´æ–°
            tracks = tracker.update(detections, frame)
            
            # å¯è§†åŒ–
            frame_info = {
                'frame_number': frame_count,
                'detections': len(detections),
                'tracks': len(tracks),
                'method': method
            }
            
            vis_frame = self.visualizer.draw_tracks(frame, tracks, detections, frame_info)
            
            # æ·»åŠ æµ‹è¯•ä¿¡æ¯
            self._add_test_info_to_frame(vis_frame, method, frame_count, tracker)
            
            # å†™å…¥è§†é¢‘
            out.write(vis_frame)
            
            # ç»Ÿè®¡ä¿¡æ¯
            frame_time = (time.time() - frame_start) * 1000
            processing_times.append(frame_time)
            
            tracking_stats.append({
                'frame': frame_count,
                'detections': len(detections),
                'tracks': len(tracks),
                'processing_time': frame_time
            })
            
            frame_count += 1
            
            # è¿›åº¦æ˜¾ç¤º
            if frame_count % 100 == 0:
                progress = (frame_count / total_frames) * 100
                print(f"â³ å¤„ç†è¿›åº¦: {progress:.1f}% ({frame_count}/{total_frames})")
        
        # æ¸…ç†èµ„æº
        cap.release()
        out.release()
        
        total_time = time.time() - start_time
        
        # è·å–æœ€ç»ˆç»Ÿè®¡
        final_stats = tracker.get_comprehensive_stats()
        
        # æµ‹è¯•ç»“æœ
        test_result = {
            'method': method,
            'test_name': test_name,
            'video_path': video_path,
            'output_video': output_video_path,
            'processing_stats': {
                'total_frames': frame_count,
                'total_detections': detection_count,
                'total_time': total_time,
                'avg_fps': frame_count / total_time,
                'avg_processing_time': np.mean(processing_times),
                'avg_detections_per_frame': detection_count / frame_count if frame_count > 0 else 0
            },
            'tracking_stats': final_stats,
            'frame_by_frame_stats': tracking_stats
        }
        
        print(f"âœ… æµ‹è¯•å®Œæˆ: {test_name} - {method}")
        print(f"ğŸ“Š å¤„ç†å¸§æ•°: {frame_count}")
        print(f"âš¡ å¹³å‡FPS: {test_result['processing_stats']['avg_fps']:.1f}")
        print(f"ğŸ¯ æ€»æ£€æµ‹æ•°: {detection_count}")
        print(f"ğŸ”„ å…¨å±€é‡ç½®: {final_stats['basic']['global_resets']}æ¬¡")
        print(f"ğŸ“ˆ ä¸ªä½“é‡ç½®: {final_stats['basic']['individual_resets']}æ¬¡")
        
        return test_result
    
    def run_comprehensive_test(self, video_path, output_dir, test_name="comprehensive"):
        """è¿è¡Œç»¼åˆæµ‹è¯•ï¼ˆæ‰€æœ‰æ–¹æ³•å¯¹æ¯”ï¼‰"""
        print(f"\n{'='*80}")
        print(f"ğŸš€ å¯åŠ¨ç»¼åˆæµ‹è¯•: {test_name}")
        print(f"{'='*80}")
        
        all_results = {}
        
        # æµ‹è¯•æ‰€æœ‰æ–¹æ³•
        for method in self.test_methods:
            try:
                result = self.run_single_test(
                    video_path, output_dir, method, 
                    f"{test_name}_{method}"
                )
                if result:
                    all_results[method] = result
            except Exception as e:
                print(f"âŒ æ–¹æ³• {method} æµ‹è¯•å¤±è´¥: {e}")
                continue
        
        # ç”Ÿæˆå¯¹æ¯”æŠ¥å‘Š
        if all_results:
            self._generate_comparison_report(all_results, output_dir, test_name)
        
        self.test_results[test_name] = all_results
        
        print(f"âœ… ç»¼åˆæµ‹è¯•å®Œæˆ: {test_name}")
        return all_results
    
    def _add_test_info_to_frame(self, frame, method, frame_count, tracker):
        """åœ¨å¸§ä¸Šæ·»åŠ æµ‹è¯•ä¿¡æ¯"""
        # æ–¹æ³•åç§°
        cv2.putText(frame, f"Method: {method.upper()}", (10, 30), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 255), 2)
        
        # å¸§ç¼–å·
        cv2.putText(frame, f"Frame: {frame_count}", (10, 60), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)
        
        # è¿åŠ¨æ£€æµ‹çŠ¶æ€
        if hasattr(tracker, 'frame_motion_info') and tracker.frame_motion_info:
            motion_info = tracker.frame_motion_info
            if motion_info['is_motion']:
                status_text = f"Motion: {motion_info['magnitude']:.1f}px"
                color = (0, 165, 255) if motion_info['should_reset'] else (0, 255, 255)
                cv2.putText(frame, status_text, (10, 90), 
                           cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 1)
        
        # è·Ÿè¸ªå™¨ç»Ÿè®¡
        active_trackers = len(tracker.trackers)
        cv2.putText(frame, f"Trackers: {active_trackers}", (10, 120), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)
    
    def _generate_comparison_report(self, results, output_dir, test_name):
        """ç”Ÿæˆå¯¹æ¯”æŠ¥å‘Š"""
        report_path = os.path.join(output_dir, f"{test_name}_comparison_report.txt")
        
        with open(report_path, 'w', encoding='utf-8') as f:
            f.write(f"ç›¸æœºè¿åŠ¨è¡¥å¿è·Ÿè¸ªç³»ç»Ÿ - å¯¹æ¯”æµ‹è¯•æŠ¥å‘Š\n")
            f.write(f"=" * 60 + "\n\n")
            f.write(f"æµ‹è¯•åç§°: {test_name}\n")
            f.write(f"æµ‹è¯•æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
            f.write(f"æµ‹è¯•æ–¹æ³•: {', '.join(results.keys())}\n\n")
            
            # æ€§èƒ½å¯¹æ¯”
            f.write("ğŸ“Š æ€§èƒ½å¯¹æ¯”\n")
            f.write("-" * 40 + "\n")
            for method, result in results.items():
                stats = result['processing_stats']
                f.write(f"{method.upper()}:\n")
                f.write(f"  å¹³å‡FPS: {stats['avg_fps']:.1f}\n")
                f.write(f"  å¤„ç†æ—¶é—´: {stats['avg_processing_time']:.2f}ms\n")
                f.write(f"  æ€»å¸§æ•°: {stats['total_frames']}\n")
                f.write(f"  æ€»æ£€æµ‹: {stats['total_detections']}\n\n")
            
            # è¿åŠ¨æ£€æµ‹å¯¹æ¯”
            f.write("ğŸ¯ è¿åŠ¨æ£€æµ‹å¯¹æ¯”\n")
            f.write("-" * 40 + "\n")
            for method, result in results.items():
                tracking_stats = result['tracking_stats']
                f.write(f"{method.upper()}:\n")
                f.write(f"  å…¨å±€é‡ç½®: {tracking_stats['basic']['global_resets']}æ¬¡\n")
                f.write(f"  ä¸ªä½“é‡ç½®: {tracking_stats['basic']['individual_resets']}æ¬¡\n")
                f.write(f"  è¿åŠ¨æ£€æµ‹ç‡: {tracking_stats['motion_detection']['motion_detection_rate']}\n")
                f.write(f"  é‡ç½®è§¦å‘ç‡: {tracking_stats['motion_detection']['reset_trigger_rate']}\n\n")
            
            # æ¨èæ–¹æ³•
            f.write("ğŸ’¡ æ¨èæ–¹æ¡ˆ\n")
            f.write("-" * 40 + "\n")
            
            # åŸºäºæ€§èƒ½å’Œæ•ˆæœé€‰æ‹©æœ€ä½³æ–¹æ³•
            best_method = self._select_best_method(results)
            f.write(f"æ¨èæ–¹æ³•: {best_method.upper()}\n")
            f.write(f"æ¨èç†ç”±: åœ¨æ€§èƒ½å’Œæ•ˆæœé—´è¾¾åˆ°æœ€ä½³å¹³è¡¡\n\n")
        
        print(f"ğŸ“‹ å¯¹æ¯”æŠ¥å‘Šå·²ç”Ÿæˆ: {report_path}")
    
    def _select_best_method(self, results):
        """é€‰æ‹©æœ€ä½³æ–¹æ³•"""
        scores = {}
        
        for method, result in results.items():
            # ç»¼åˆè¯„åˆ†ï¼šæ€§èƒ½ + æ•ˆæœ
            fps_score = result['processing_stats']['avg_fps'] / 30.0  # æ ‡å‡†åŒ–FPS
            reset_effectiveness = (result['tracking_stats']['basic']['global_resets'] + 
                                 result['tracking_stats']['basic']['individual_resets'])
            
            # æƒé‡è¯„åˆ†
            scores[method] = fps_score * 0.3 + min(reset_effectiveness / 10.0, 1.0) * 0.7
        
        return max(scores, key=scores.get)


def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("ğŸš€ ç›¸æœºè¿åŠ¨è¡¥å¿è·Ÿè¸ªç³»ç»Ÿ - æµ‹è¯•ç¨‹åº")
    print("=" * 60)
    
    # é…ç½®å‚æ•°
    model_path = "/home/mingxing/worksapce/ultralytics/small_target_detection/yolov8_small_aircraft/weights/best.pt"
    video_path = "/home/mingxing/worksapce/ultralytics/vedio/vedio/short.mp4"
    output_dir = "/home/mingxing/worksapce/ultralytics/camera_motion_compensation/test_results"
    
    # æ£€æŸ¥æ–‡ä»¶
    if not os.path.exists(model_path):
        print(f"âŒ æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {model_path}")
        return
    
    if not os.path.exists(video_path):
        print(f"âŒ è§†é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {video_path}")
        return
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    os.makedirs(output_dir, exist_ok=True)
    
    # åˆå§‹åŒ–æµ‹è¯•ç³»ç»Ÿ
    test_system = CameraMotionCompensationTestSystem(model_path, conf_threshold=0.1)
    
    print(f"ğŸ“ è¾“å‡ºç›®å½•: {output_dir}")
    print(f"ğŸ¯ ä½¿ç”¨æ¨¡å‹: {model_path}")
    print(f"ğŸ“º æµ‹è¯•è§†é¢‘: {video_path}")
    
    # è¿è¡Œç»¼åˆæµ‹è¯•
    results = test_system.run_comprehensive_test(
        video_path, output_dir, "motion_compensation_v1"
    )
    
    if results:
        print(f"\n{'='*60}")
        print("âœ… æ‰€æœ‰æµ‹è¯•å®Œæˆï¼")
        print(f"ğŸ“Š æµ‹è¯•äº† {len(results)} ç§æ–¹æ³•")
        print(f"ğŸ“ ç»“æœä¿å­˜åœ¨: {output_dir}")
        print("=" * 60)
    else:
        print("âŒ æµ‹è¯•å¤±è´¥ï¼")


if __name__ == "__main__":
    main()
